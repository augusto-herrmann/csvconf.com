id,name,title,abstract,title-es,abstract-es,img,github,twitter,slides_url,talk_url
awilliams,Adrienne Williams,Data Is Power: How Unpaid labor & Stolen Data Train Amazon’s Technology & How Workers Can Take Their Power & Their Money Back.,"Amazon uses sensors in delivery vans and collects data through the Mentor app and company-issued scanners. Mentor is mandatory.  It monitors “risky” driving and distraction behind the wheel. Drivers are required to complete unpaid homework based on perceived “mistakes” determined by Mentor. Low scores means uninsurable drivers. Most drivers download the app onto personal phones instead of the company-provided scanners provided. To download the app onto one's personal phone means employees must allow Mentor to run in the background…always. In this talk, I will draw on my experience as a former Amazon delivery driver and organizer to discuss how tools implemented by Amazon to surveil its workers are, at the same time, used to collect workers' data and train future surveillance systems. This creates a vicious cycle that negatively affects workers. In my talk, I will describe how Amazon’s priorities shape the data that is collected, and how workers develop collective and individual strategies to trick the surveillance systems and regain control of the data that is collected from them.",Los datos son poder: cómo el trabajo no remunerado y los datos robados entrenan la tecnología de Amazon y cómo los trabajadores pueden recuperar su poder y su dinero.,"Amazon utiliza sensores en las furgonetas de reparto y recopila datos a través de la aplicación Mentor y de escáneres proporcionados por la empresa. Mentor es obligatorio. Controla la conducción ""de riesgo"" y las distracciones al volante. Los conductores deben hacer deberes no remunerados en función de los ""errores"" percibidos y determinados por Mentor. Las puntuaciones bajas significan conductores no asegurables. La mayoría de los conductores descargan la aplicación en sus teléfonos personales en lugar de hacerlo en los escáneres proporcionados por la empresa. Descargar la aplicación en el teléfono personal significa que los empleados deben permitir que Mentor se ejecute en segundo plano... siempre. En esta charla, me basaré en mi experiencia como antiguo conductor de reparto y organizador de Amazon para hablar de cómo las herramientas implementadas por Amazon para vigilar a sus trabajadores se utilizan, al mismo tiempo, para recopilar datos de los trabajadores y formar futuros sistemas de vigilancia. Esto crea un círculo vicioso que afecta negativamente a los trabajadores. En mi charla, describiré cómo las prioridades de Amazon determinan los datos que se recogen y cómo los trabajadores desarrollan estrategias colectivas e individuales para engañar a los sistemas de vigilancia y recuperar el control de los datos que se recogen de ellos.",https://www.dair-institute.org/about,,adrienneandgp,,
ahanna,Alex Hanna,Keynote,,Cambiando el marco: Los trabajos de ImageNet y los datos de IA,"Las tecnologías de inteligencia artificial (IA) como ChatGPT, Stable Diffusion y LaMDA han dado lugar a una industria multimillonaria de IA generativa y a una industria potencialmente mucho mayor de IA en general. Sin embargo, estas tecnologías no existirían si no fuera por la inmensa cantidad de datos que se extraen para hacerlas funcionar, la mano de obra de anotación mal pagada y explotada necesaria para el etiquetado y la moderación de contenidos, y los cuestionables acuerdos en torno al consentimiento para utilizar estos datos. Aunque los conjuntos de datos utilizados para entrenar y evaluar los modelos comerciales suelen quedar ocultos bajo el velo del secreto comercial, podemos aprender mucho sobre estos sistemas interrogando a determinados conjuntos de datos de acceso público que se consideran fundamentales en la investigación académica de la IA.

En esta charla, investigaré un único conjunto de datos, ImageNet. No es exagerado decir que sin ImageNet no tendríamos la actual ola de técnicas de aprendizaje profundo que impulsan casi todas las tecnologías modernas de IA. Comienzo desde tres puntos de vista: la historia de ImageNet desde la perspectiva de sus conservadores y su predecesor lingüístico WordNet, el testimonio de los anotadores de datos que etiquetaron millones de imágenes de ImageNet, y los sujetos de los datos y los creadores de las imágenes dentro de ImageNet. Desde el punto de vista académico, sitúo este análisis dentro de una teoría y una práctica más amplias de los estudios sobre infraestructuras. Desde el punto de vista práctico, apunto a una visión de la tecnología que no se base en prácticas de extracción de datos sin restricciones, explotación laboral y uso de imágenes sin el debido consentimiento.",,,,,
achowdhary,Anand Chowdhary,Running a Covid-19 nonprofit as a data maker,"In 2020, Anand Chowdhary and his team founded Karuna 2020, a nonprofit that distributed masks and food to migrant laborers and frontline workers in India. Using GitHub Actions, we developed several open-sourced workflows that automate tasks like generating open data APIs. For example, for every ration kit we distributed, we uploaded a face-blurred photo of the recipient and our REST API tells donors exactly where we're spending the money. All of this was built using Airtable, GitHub Actions, and CSV spreadsheets. In this talk, fellow data makers will learn about how we used automated processes for complete data transparency and the tooling we developed for running a nonprofit.",Dirigir una organización sin ánimo de lucro Covid-19 como creador de datos,"En 2020, Anand Chowdhary y su equipo fundaron Karuna 2020, una organización sin ánimo de lucro que distribuía máscaras y alimentos a trabajadores migrantes y de primera línea en la India. Gracias a GitHub Actions, desarrollamos varios flujos de trabajo de código abierto que automatizan tareas como la generación de API de datos abiertos. Por ejemplo, por cada kit de raciones que distribuimos, subimos una foto con la cara difuminada del receptor y nuestra API REST informa a los donantes exactamente de dónde gastamos el dinero. Todo esto se construyó utilizando Airtable, GitHub Actions y hojas de cálculo CSV. En esta charla, los creadores de datos aprenderán cómo utilizamos los procesos automatizados para una completa transparencia de los datos y las herramientas que desarrollamos para gestionar una organización sin ánimo de lucro.",https://anandchowdhary.com/anand.png,AnandChowdhary,AnandChowdhary,,
aanand,Apoorv Anand,A community driven initiative to crowdsource background details of 1700 High Court Judges in India,"India, the world's largest democracy, has a complex judicial system. The judgments delivered by courts touch upon almost every aspect of an individual's life. Despite playing a critical role, there is barely any data available on the background of judges in these courts. This information is crucial in building and sustaining public trust in the judicial process. It is also critical to inform about potential bias and conflicts of interest. The conceptualization of this dataset was a response to this information gap in India's judicial architecture.
We launched a campaign to build a public dataset titled Know Your High Court Judges (KHOJ) (https://justicehub.in/initiatives/khoj-india) to curate background information on judges. Over 15 months, we collected data on 43 variables on the judge's demographic, education, work experience, judicial appointments, transfers, etc. More than 30 students from law universities across the country, collaborated on crowd-sourcing data from court websites, and other publicly available documents on official websites.
In this talk, I would like to discuss: 
1. The story behind the conceptualization of this dataset
2 - The crucial roles played by members of the Justice Hub (https://justicehub.in/) community 
3 - The process of curating data and ensuring the accuracy of data points (collected by volunteers who had little to no background in working with data or technology) 
4 - Our learnings about how collaborative data curation processes can be used to collect data on other governance-related indicators that are not readily available and difficult to access through the Right to Information Act. 
5 - How this dataset has been contributing to building a discourse around transparency in judicial decision-making.",https://civicdatalab.in/team/apoorv,https://github.com/apoorv74,,,
aibrahim,Ayyub Ibrahim,Investigating police misconduct and migratory patterns,"After gathering public records from hundreds of police departments and consolidating them into a single unified data structure, we were able to track individual police officers who move from one city to another after being accused of serious misconduct. 
In the course of investigating this and other systemic failures of the accountability system, we built a public database ( http://LLEAD.co ) and we cultivated a network of real-world practitioners who can put this tool to work on a day-to-day basis by using it to: defend individual members of the public against wrongful convictions ( https://ip-no.org ) , illustrate the mechanics of police impunity ( https://copwatchnola.wordpress.com ) , and advocate for meaningful changes on the policy level and beyond. 
In this talk, we will share techniques that we’ve developed for assembling individual profiles from a dynamic system made up of many messy data sources without any single unique identifier and we will discuss the challenges/opportunities for using data as a tool to transfer power to the public.",,,,,
bgreshaketzovaras,Bastian Greshake Tzovaras,"Nothing about us, without us: Participatory approaches to make data by the people for the people","Data and AI have by now entered most – if not all – aspects of our lives, from the social over health to the workplace. With this datafication come myriad ethical questions: Which data should (and should not) be collected? What are acceptable uses for those data? And importantly, who gets to decide on these questions? More often than not, these questions are neither posed to nor answered by the people most affected by the data collection and might only be asked once harm has been done. Participatory approaches such as citizen science can be used to give those affected a voice by involving them right from the start and provides a pathway to improving data justice more broadly. This talk will give concrete examples to highlight how participation in fields such as transgender healthcare, Autism research and chronic diseases have been implemented and not only solved some of these issues, but also lead to better and more impactful research as a result. Furthermore, we will give a set of recommendations and ideas on how to start implementing such approaches in your own data practice.",https://tzovar.as/assets/images/profile.jpg,gedankenstuecke,gedankenstuecke,,
cgreenwood,Cathi Greenwood,Speed Bumps on the Road to Innovating with Government Open Data ,"Along with improving transparency and efficiency, open government data is supposed to support entrepreneurship, in the form of user-friendly apps and other business innovations. But the reality often falls short of the ideal. Developers who want to use government data run into poor data quality and documentation, insufficient off-the-shelf data products, limited options for automation and other stumbling blocks. The Washington state (US) open government data team will highlight common development barriers and ways to overcome them, using examples from state agencies’ efforts to open data on transit, internet access, legal cannabis, licensing and more.",,,,,
dcarranza,Daniel Carranza,From garbage data to data on garbage,"Since 2013 on Data Uruguay we’ve been using open data to help people classify and correctly dispose recyclables. We centralise information on hundreds of initiatives in Uruguay and Colombia through DondeReciclo.uy and DondeReciclo.co, and we’re currently working on the national industrial waste tracking system with the ministry of the environment. We want to share the model and strategies we use to clean, standarise, visualise and publish data from dozens of private and públic stakeholders, through a project that has been fiantially sustainable for nine years.",https://drive.google.com/file/d/1TCVsCVx9JG4S37pKcbVUc4Z6fM-vNWfR/view?usp=drivesdk,danielcarranza,danielcarranza,,
dbarnes,Darren Barnes,UK government: Building better data for a better future,How the UK's Office for National Statistics is leading a revolution across government organisations to bake CSV-W standard into the statistical production process by default. Our future is to pioneer an approach for delivering our statistics as linked open data for the web and build innovative and semantically correct data that can bring our data to life and tell stories that are accessible to everyone.,,,,,
dmesquita,Deborah Mesquita,Identifying DDoS attacks on IoT devices using deep learning,"The ESP32 is a series of microcontrollers with integrated Wi-Fi. They offer an opportunity to empower a variety of IoT projects and users because they’re both low-cost and low-power. Security should be an essential part of the development of IoT systems, and these devices are easy targets for cyberattacks because of the poor cycles of update and maintenance. In this talk, we’ll see how we used deep learning and network traffic analysis knowledge to train and embed a model on the ESP32 capable of preventing DDoS attacks. IoT and machine learning combined can solve a lot of today’s problems (including problems of developing countries) and our main goal is to show with low-cost devices we can bring IoT project ideas to real life.",https://avatars.githubusercontent.com/u/2621484?v=4,https://github.com/dmesquita,,,
dbaker,Dylan Baker,Datasets Have Worldviews: Understanding Classification In Your Data,"The classification schemes that structure our datasets come with their own politics and histories. How do we uncover the values underpinning our data classification schemes, and what do we do when we find them? In this talk, we start by diving into the harmful real-world effects that different classification schemes can have. Then, we explore ways we can uncover the values hiding in our own data, and highlight different ways to mitigate harms perpetuated by the (always-imperfect) categorizations we make.",https://drive.google.com/file/d/1_A5VjjAih4RQEJd5dn68XjKKl5nwrJjQ/view?usp=share_link,,dylnbkr,,
dgonzales,David Gonzalez,Cómo encontrar pistas para tus investigaciones en cientos de datasets usando Aleph,"Descripción: ¿Tienes bases de datos propias que te gustaría cruzar con otros datasets para ver si nombres de empresas y personas aparecen mencionados? ¿Tu redacción/organización trabaja con muchos PDF y necesitás una herramienta que extraiga el texto para poder hacer búsquedas de palabras clave? ¿Tienes una carpeta de documentos que quieres trabajar de manera segura con tus colegas?
¡Aleph puede ayudarte! Esta plataforma creada por OCCRP creada ayuda a periodistas, activistas e investigadores a ""seguir el rastro del dinero"". Su modelo de organización de datos, llamado Follow the Money (FTM) permite organizar grandes bases en un entorno seguro para encontrar conexiones entre personas y empresas a través del cruce de entidades en los datasets. 
Durante la sesión mostraremos cómo usar la herramienta a través de ejemplos concretos y de investigaciones reales. Nuestro demo en vivo, facilitará la conversación y preguntas con la audiencia.",https://www.occrp.org/en/aboutus/staff/eduardo-goulart,,deolhonosdados ,,
elkisa,Emma Laura Kisa,Opening up African Data,"A lot of data published by African governments and other institutions are stuck in pdf reports or websites. To solve this problem, Code for Africa built an open data portal called openAFRICA which is the continent's largest volunteer-driven portal. openAFRICA contains more than 6,000 African related datasets on various topics that are in a machine-readable format. openAFRICA promotes liberating data and the reuse and sharing of this open data.",https://drive.google.com/file/d/1gWeLscUj5tYZNojoPcVxL45AJ5Gikjav/view?usp=sharing,,ELNamwanje,,
ekarev,Evgeny Karev,Frictionless Application (IDE for CSV),"This talk will present a new data management IDE for CSV and other formats that provides functionality to describe, extract, validate, and transform tabular data. It's a logical continuation of the Frictionless Data project's standards and software with a focus on the non-technical audience: data publishers, librarians, and, in general, people who prefer visual interfaces over command-line interfaces and programming languages.",https://media-exp1.licdn.com/dms/image/C4D03AQEkDaXReUCMJg/profile-displayphoto-shrink_400_400/0/1589806579438?e=1673481600&v=beta&t=OwUxnWGUjHcoNsxVxMYi-jqXK5IEbYgV-VeYbt_Rkf4,roll,,,
,Esha Datta,What are you? Automating journal subject classification,"Traditionally, journal subject classification was done manually at varying levels of granularity, depending on the use case for the institution. Automating classification work surfaces questions about the relevance of the taxonomy used, the potential bias that might exist, and the texts being classified. Currently, journals are classified using various taxonomies and are siloed in many systems such as library databases or software for publishers. Providing a service that can automatically classify (and provide a measure of accuracy!) a text outside of a specific system can democratize access of this information across all systems. Crossref provides a range of services to the research community; we have a wealth of metadata deposited by the community. We wondered how we could contribute in this area. I will be talking about the ways in which I processed journal metadata, generated features based on that, ran machine learning models, measured their accuracy, and experimented with word and sentence embedding with Allen AI’s Scibert and other deep learning models. As a work in progress, I look forward to sharing more details in the talk, including the efficacy of the automated system in place as well as talking about the taxonomies investigated so far.",,eshadatta-crossref,,,
fppenna,Félix Pedro Penna,Datos de contrataciones públicas: dónde encontrarlos y cómo utilizarlos,"¿Cuánto dinero gastan los gobiernos para llevar adelante sus políticas públicas? ¿Es posible saber cuáles son los bienes o servicios que demandan y cuánto pagan por ello? ¿Quiénes son las personas y empresas que más se benefician de estos contratos? Los datos abiertos de contrataciones son una herramienta poderosa para responder a estas y otras preguntas y ofrecer información valiosa para ciudadanos y organizaciones de todo el mundo. En esta conversación se presenta el Data Registry de Open Contracting Partnership, uno de los más grandes repositorios de datos de contrataciones públicas, que disponibiliza cientos de GB de datos (¡estandarizados!) en formatos abiertos. Los datos se vuelven útiles cuando se utilizan: como bonus track, esta presentación indica cuáles son los pasos claves para sacar provecho de los datos en el monitoreo del gasto público o la búsqueda de oportunidades de negocio. ",https://drive.google.com/file/d/1omeVgUmuE53CZm3iLWS6HTmj-FmWQevf/view?usp=share_link,fppenna,fppenna,,
faruiz,Fernanda Aguirre Ruiz,Organize your data analysis; use a project template,"Every time we start a data-driven project, we invest part of our time creating and configuring that new project. However, with the help of Cookiecutter it is enough to execute a command to have the whole procedure solved by means of a project template.  When we work with data, we handle different versions of our databases, graphics and code files. This can result in disorganized and difficult to access projects, so when we use project templates we can automate this repetitive work by creating files and folders structured in a certain way to help us easily locate the different sections and standardize our projects. At the same time we can also automate more complex proceedings that we have incorporated in our workflows, such as installing certain libraries, starting git repositories, creating virtual environments, among many other possibilities.  ",https://drive.google.com/file/d/17q9lyLSZtSSzygGoBsRJvJABxx7_sOwr/view?usp=sharing,fer-aguirre,feragru,,
fcampagnucci,Fernanda Campagnucci,Querido Diário': how an open source project is freeing official municipal records for 45 million people in Brasil (and counting!),"There are 5,570 cities and 26 states with the autonomy to design and implement policies in Brazil. Since there is no centralized place to look for the decision-making acts of these entities, the only reliable source of information is the official gazettes (or records), published in a closed and unstructured way in PDF files. The manual work of analyzing this mass of information is virtually impossible. To fill this data void, ​​we created an infrastructure capable of collecting, processing, and openly making this information available. The ""Querido Diario"" (""Dear Diary"" – a witty wordplay in reference to the official gazettes in Portuguese) MVP was launched more than a year ago and has been scaled and improved since then. With the help of a vibrant community, it has collected the entire time series of official diaries, creating a repository of more than 144,000 files, and started collecting them daily.",https://drive.google.com/file/d/1Ip1fmhd0ogDIM2Vj3DpzUQxgbQQiErkz/view?usp=share_link,campagnucci,fecampa,,
fakara,Florence Akara,Inclusive data narratives - decolonising data for Africa,"Universal access to data and tech can only be achieved by engaging from the bottom up. The challenge, however, lies in the narrative it holds for many Africans, particularly in rural areas. Colonization taught our African forefathers to survive, and this was passed down through generations. To openly engage with tech and data is not a usual thing in our community, the survival mode is to prevent it from infiltrating our communities, particularly the rural ones. Tech and data are categorised as skilled professions, and many, even myself, find ourselves apprehensive about the potential threats, and weaknesses we could expose ourselves by engaging in it. In East Africa, people are daily victims of data infringements and fraud, women in particular. It doesn't help that most data and tech programs are often led by non-locals and men; ineffectively distancing the women, and local communities from feeling like active participants or collaborators in any tech or data agendas. Because they are often expensive, data and tech are perceived as inaccessible for the lower economic communities, and a luxury for most people in general. Governments themselves don't have adequate resources to properly train and engage local communities, which means its access is inevitably limited. The lack of locally accessible, free or affordable data and tech, fails to match the need for legitimate equitable access. This results in fewer people engaging in data, because of a lack of adequate information to make informed decisions about the type of data they are comfortable sharing, its storage and usage - outweighing much interest in engaging in it. Sharing stories, and developing a new narrative for data inclusion in Africa, abolishing the hierarchies of who can use data, by enabling local actors to equally access them without cost barriers. Spotlighting women and girls in particular, engaging without fear of online exploitation, or abuse, prioritising feminist values so they do not shy from self-marketing, and building their capacity so they can adopt it to their communities, will alleviate a significant barrier to the data inclusion agenda. Better access to tech and data will result in significant improvements to impact investment and achieve SDG impact. My initiative, collabo254 is working to invest in local organisational development, ensuring that their capacity, particularly in updating its use of basic, free tech tools to collect data. Designed from my own experience running a nonprofit for over 5 years, and forced to learn to self-design from google suites tools and another free basic tech, to fit our local team needs, and user challenges and align with our model of reporting to better manage records of our impact without breaking the bank. The idea is to make data and tech not appear as threatening and work with local faces and names, so that communities can see themselves represented in data spaces, to alleviate the fear of actively engaging.",,,FemmeInt,,
gmejias,Gabriela Mejias,Open research needs open (meta)data,"Metadata plays a key role in the scientific publication and dissemination process. It is only through metadata and identifiers  that each contribution, from research data to  article publication and beyond, becomes findable, accessible, interoperable and reusable. Persistent identifiers (PIDs) and their metadata are the backbone of scholarly communications, since only through them can the promise of sustainable access to research information be realized.  This presentation will highlight the importance of open metadata in scholarly communications to recognize a wide range of contributions to science and as a way to build trust in research.  We will also discuss the need for collaborative, community efforts to improve metadata creation and dissemination. Examples of organizations and researchers using open metadata will be presented.",https://datacite.org/team.html,gmejias,gabioshka,,
grosati,Germán Rosati,Land use trajectories as text data,"How does land use change over time? Can agrarian frontier expansion and deforestation be detected in high resolution images over a long period of time? This question has implications in both environmental and socio-economic dimensions. Since the publication of large government databases derived from processed satellite images, new analytical and methodological approaches have emerged
Problems of this kind are usually addressed by aggregating information at higher levels (municipalities, departments, administrative areas). For this talk we propose another approach: to work at the pixel level. We will represent each land use pixel sequence over time as if it were a word. This makes it possible to use the so-called “edit distances” (which measure the number of operations necessary to transform one sequence into another) and to generate a matrix that allows clustering land use trajectories using simple techniques. 
We will present an illustration of this procedure covering the 1992-2020 period in Argentina (excluding Patagonia region), using information from the European Space Agency and Dynamic World. Our main goal is to obtain a map with the highest possible resolution that shows the following situations: 1) areas of recent expansion of the agrarian frontier; 2) areas of “consolidated” agriculture and 3) areas of recent urban expansion. We will present some cool visualizations of these trajectories and their spatial distributions.",Trayectorias de uso del suelo como datos de texto,"¿Cómo cambia el uso del suelo a lo largo del tiempo? ¿Pueden detectarse la expansión de la frontera agraria y la deforestación en imágenes de alta resolución durante un largo periodo de tiempo? Esta pregunta tiene implicaciones tanto en la dimensión medioambiental como en la socioeconómica. Desde la publicación de grandes bases de datos gubernamentales derivadas de imágenes de satélite procesadas, han surgido nuevos enfoques analíticos y metodológicos.
Los problemas de este tipo suelen abordarse agregando información a niveles superiores (municipios, departamentos, áreas administrativas). Para esta charla proponemos otro enfoque: trabajar a nivel de píxel. Representaremos cada secuencia de píxeles de uso del suelo a lo largo del tiempo como si fuera una palabra. Esto permite utilizar las llamadas ""distancias de edición"" (que miden el número de operaciones necesarias para transformar una secuencia en otra) y generar una matriz que permite agrupar las trayectorias de uso del suelo mediante técnicas sencillas. 
Presentaremos una ilustración de este procedimiento que cubre el período 1992-2020 en Argentina (excluyendo la región patagónica), utilizando información de la Agencia Espacial Europea y Dynamic World. Nuestro objetivo principal es obtener un mapa con la mayor resolución posible que muestre las siguientes situaciones 1) áreas de expansión reciente de la frontera agraria; 2) áreas de agricultura ""consolidada"" y 3) áreas de expansión urbana reciente. Presentaremos algunas visualizaciones interesantes de estas trayectorias y sus distribuciones espaciales.",http://investigadores.unsam.edu.ar/rest/img/fotos/Rosati-German-Federico.jpg,gefero,Crst_C,,
gsollazzo,Giuseppe Sollazzo,Keynote - Talking with data – stories and lessons from my data adventures,"Before his current role in the UK National Health Service as Deputy Director of the Artificial Intelligence Lab and Head of AI Skunkworks, Giuseppe's career journey included being a data wrangler, an open data activist, a computational research data support officer, and the Head of Data of a Government Department. This keynote will tell some stories from this 15-year long journey, and share the lessons Giuseppe has learned.",Hablar con los datos: historias y lecciones de mis aventuras con los datos,"Esta ponencia ofrecerá un relato desenfadado de algunas de las lecciones comunes aprendidas al ""hablar con datos"" como gestor de datos, activista y en el gobierno central.",,,,,
hdebat,Humberto Debat,Virus discovery at a global scale: a sustainable blueprint based on secondary analyses of open sequencing data,"Viruses are the most prevalent biological entities on earth. Notably, conservative estimates suggest that over 99.9% of the virosphere remains elusive. In this talk I will present novel strategies oriented to uncover the global viral dark matter based on secondary analyses of publicly available open sequencing data. Examples of robust detection and characterization of novel viruses with zoonotic competence with a focus in Latin America will be described. The potential impact in virus emergence and pandemic prediction will be discussed.",Descubrimiento de virus a escala mundial: un plan sostenible basado en análisis secundarios de datos de secuenciación abiertos,"Los virus son las entidades biológicas más prevalentes de la Tierra. Sin embargo, estimaciones conservadoras sugieren que más del 99,9% de la virosfera permanece oculta. En esta charla presentaré estrategias novedosas orientadas a descubrir la materia oscura viral global, basadas en análisis secundarios de datos de secuenciación abiertos y disponibles públicamente. Se describirán ejemplos de detección y caracterización sólidas de nuevos virus con competencia zoonótica, con especial atención en América Latina. Se discutirá el impacto potencial en la emergencia de virus y la predicción de pandemias.",https://drive.google.com/file/d/1Cbio70qgFuvvaojlaAbpT70FyCoU-CcO/view?usp=drivesdk,humbertodebat,humbertodebat,,
irpérez,Irene Ramos Pérez,Demonstrate to users and funding sources the public value of the Agrobiodiversity Information System in Mexico.,"We will present the strategies we have implemented to demonstrate to users and funding sources the public value of the Agrobiodiversity Information System (SIAgroBD) of the National Commission for the Knowledge and Use of Biodiversity (CONABIO). CONABIO is a government institution that compiles, analyzes and publishes data related to biodiversity and natural resources in Mexico. SIAgroBD is part of the GEF Mexican Agrobiodiversity Project, with FAO as the implementing agency. The objective of SIAgroBD is to generate, systematize and publish open data related to native crops of global relevance, including biological, geographic, agronomic, nutritional and cultural information. We will share the challenges we have faced in advocating for the development and maintenance of the SIAgroBD with different key stakeholders, such as funding sources and users, as well as strategies to address them. In particular, we highlight the need to build a common ground on the functionalities of an information system through capacity building; the incorporation of feedback processes with the user community, for example, through surveys or focus groups; and the design of narratives adapted to the expectations of different user profiles. These strategies have helped us to communicate the scope of the system, promote the adoption of our tools and, more broadly, show how the SIAgroBD can support decision making on conservation and food security issues. The lessons we have learned could be useful for other projects that need to demonstrate the public value of open data infrastructures in contexts where there are limited incentives for such developments.",Demostrar a personas usuarias y fuentes de financiamiento el valor público del Sistema de Información de Agrobiodiversidad en México,"Presentaremos las estrategias que hemos implementado para demostrar a personas usuarias y a fuentes de financiamiento el valor público del Sistema de Información de Agrobiodiversidad (SIAgroBD) de la Comisión Nacional para el Conocimiento y Uso de la Biodiversidad (CONABIO). CONABIO es una institución gubernamental que compila, analiza y publica datos relacionados con la biodiversidad y los recursos naturales en México. El SIAgroBD forma parte del Proyecto GEF de Agrobiodiversidad Mexicana, que tiene a la FAO como agencia implementadora. El objetivo del SIAgroBD es generar, sistematizar y publicar datos abiertos relacionados con cultivos nativos de relevancia global, incluyendo información biológica, geográfica, agronómica, nutricional y cultural. Compartiremos los retos que hemos enfrentado para abogar por el desarrollo y mantenimiento del SIAgroBD con diferentes actores clave, como fuentes de financiamiento y personas usuarias, así como las estrategias para atenderlos. En particular, destacamos la necesidad de construir un piso común sobre las funcionalidades de un sistema de información a través del desarrollo de capacidades; la incorporación de procesos de retroalimentación con la comunidad de usuarios, por ejemplo, mediante encuestas o grupos focales; y el diseño de narrativas adaptadas a las expectativas de diferentes perfiles de usuarios. Estas estrategias nos han ayudado a comunicar los alcances del sistema, a promover la adopción de nuestras herramientas y, de forma más amplia, mostrar cómo el SIAgroBD puede apoyar la toma de decisiones en temas de conservación y seguridad alimentaria. Las lecciones que hemos aprendido podrían ser útiles para otros proyectos que requieran demostrar el valor público de infraestructuras para datos abiertos, en contextos donde hay incentivos limitados para estos desarrollos.",https://drive.google.com/file/d/19exNgJXA-I9vZODrBtHKJmuTspxpxNpW/view?usp=share_link,iramosp,,,
ifeldfeber y yquirog,Ivana Feldfeber y Yasmín Quirog,Collecting data on gender-based violence in Latin American judiciaries,"In this talk we will present the joint work we are doing from DataGénero - Observatory of Data with a Gender Perspective and the Contraventional, Criminal and Misdemeanor Court No. 10 of the City of Buenos Aires, to build a tool (software) that generates structured data from unstructured data. Our software is called AymurAI, which in Quechua means harvest. We want to ""harvest"" data on judicial decisions on gender violence cases. Our tool uses rules and entity recognition (NER) to extract key information from court documents, goes through a validation screen and then structures the collected information into a gender-sensitive open dataset. Through this project we want to promote open justice, open government, open data with a gender perspective and the visibility of urgent problems through data.",Recolectando datos sobre violencias de género en los poderes judiciales latinoamericanos,"En esta charla presentaremos el trabajo en conjunto que estamos realizando desde DataGénero - Observatorio de Datos con Perspectiva de Género y el Juzgado N°10 Contravenciona, Penal y de Faltas de la Ciudad de Buenos Aires, para construir una herramienta (software) que genere datos estructurados a partir de datos no estructurados. Nuestro software se llama AymurAI que en quechua significa cosecha. Queremos ""cosechar"" datos sobre resoluciones judiciales sobre casos de violencia de género. Nuestra herramienta utiliza reglas y reconocimiento de entidades (NER) para extraer información clave de documentos judiciales, pasa por una pantalla de validación y luego estructura la información recolectada en un set de datos abiertos con perspectiva de género. A través de este proyecto queremos promover la justicia abierta, el gobierno abierto, los datos abiertos con perspectiva de género y la visibilización de problemáticas urgentes a través de los datos.",https://drive.google.com/file/d/1nIIDLYoYFepZ1rGWOZD_l239Yu_Dl9mB/view?usp=share_link,ivanafeldfeber,ivanafeld,,
jformoso y lascenzi y mrajngewerc y ploto,Jesica Formoso y Laurel Ascenzi y Mariela Rajngewerc y Patricia Loto,Communities of practice in Latin America and their influence on the dissemination of open science,"The open science movement has emerged in recent years mainly as a response to the replicability and reproducibility crises faced by different branches of science and seeks to ensure the transparency of research work by sharing the different stages of the workflow. More recently, different organizations have begun to promote these values through the development of public policies and the financing of projects. However, these measures vary greatly depending on the region. One possible tool for open science dissemination, potentially with more user acceptance, is communities of practice, self-organized and self-maintained groups of people who share a concern or passion for something they do and learn how to do it better as they interact regularly. A great growth of these communities has been observed in recent years in Latin America, many aimed at reducing the gender gap in STEAM such as R-Ladies, PyLadies, GeoChicas, TecnoLatinas and Women in Bioinformatics and Data Science Latin America, others focused on transmitting skills to teach computational tools such as The Carpentries or dedicated to teach open science tools and practices such as MetaDocencia. In this context, we ask ourselves what is the role of communities of practice in the dissemination and implementation of open science practices in general, and specifically, in the Latin American region. To this end, we conducted an exploratory analysis of the evolution of the use of the terms ""open science"" and ""open science"" over time from 2012 to the present. Where information was available, the representation of each region was studied. Finally, a social network analysis was performed to identify influential users and clusters of users and then the association of these with communities of practice was studied.",Comunidades de práctica en Latinoamérica y su influencia en la difusión de la ciencia abierta,"El movimiento de ciencia abierta emerge en los últimos años como respuesta principalmente a las crisis de replicabilidad y reproducibilidad por la que atraviesan distintas ramas de la ciencia y busca garantizar la transparencia de los trabajos de investigación compartiendo las distintas etapas del flujo de trabajo. Más recientemente, distintos organismos han comenzado a promover estos valores desde el desarrollo de políticas públicas y la financiación de proyectos Sin embargo, estas medidas varían mucho dependiendo de la región. Un instrumento posible para la difusión de la ciencia abierta, potencialmente con más aceptación de los usuarios, son las comunidades de práctica, grupos auto-organizados y auto-mantenidos de personas que comparten una preocupación o pasión por algo que hacen y aprenden a hacerlo mejor a medida que interactúan con regularidad. Se ha observado un gran crecimiento de estas comunidades en los últimos años en Latinoamérica, muchas dirigidas a reducir la brecha de género en STEAM como R-Ladies, PyLadies, GeoChicas, TecnoLatinas y Women in Bioinformatics and Data Science Latin America, otras enfocadas en transmitir habilidades para enseñar herramientas computacionales como The Carpentries o dedicadas a enseñar herramientas y prácticas de ciencia abierta como MetaDocencia. En este contexto, nos preguntamos cuál es el rol de las comunidades de práctica en la difusión e implementación de prácticas de ciencia abierta en general, y específicamente, en la región de Latinoamérica. Para ello, realizamos un análisis exploratorio de la evolución del uso de los términos “ciencia abierta” y “open science” con el tiempo de 2012 a la actualidad. Se estudió, en aquellos casos en que existía información al respecto, la representación de cada región. Finalmente, se realizó un análisis de redes sociales para identificar usuarios influyentes y agrupaciones de usuarios y luego se estudió la asociación de estos con comunidades de práctica.
Somos cuatro autoras: Jesica Formoso, Laurel Ascenzi, Patricia Loto y Mariela Rajngewerc",,MetaDocencia,metadocencia,,
jkerl,John Kerl,Miller: a swiss-army chainsaw for CSV and more,"Miller (`mlr`) is one of many command-line tools available for modern data processing. In this talk, we'll start from the basics of CSV manipulation: querying, sorting, converting to/from TSV and JSON, etc. We'll peek at some of the expressive things you can do using Miller's query language -- as well as some very simple and powerful things you can do without it. We'll see how Miller is useful for non-programmers as well as programmers: data analysts, system admins, researchers, etc. https://miller.readthedocs.io/en/latest/",Miller: una motosierra de ejército suizo para sus datos CSV y más,"Miller (`mlr`) es una de las muchas herramientas de línea de comandos disponibles para el procesamiento moderno de datos. En esta charla, empezaremos por los aspectos básicos de la manipulación de CSV: consulta, ordenación, conversión a/desde TSV y JSON, etc. Veremos algunas de las cosas más expresivas que se pueden hacer utilizando el lenguaje de consulta de Miller, así como algunas cosas muy sencillas y potentes que se pueden hacer sin él. Veremos cómo Miller es útil tanto para no programadores como para programadores: analistas de datos, administradores de sistemas, investigadores, etc. https://miller.readthedocs.io/en/latest/",https://johnkerl.org/pix/heads-icons-etc/jk-2020-09.jpg,johnkerl,hachyderm.iojohnkerl,,
jddsantos,Juan De Dios Santos,Baking bread on Sundays makes me happy,"I've been tracking my mood and activities for over 1000 days. What started as a time sink eventually became my daily meditation; my time to recap the day's moments, be genuine with myself, and ask, ""how am I feeling?"" This talk is a journey that explains how I felt during those 1000 days and how my daily activities influence my mood. This talk, which will be my most personal and intimate, will contain data visualizations, statistics, time series analysis, and fun anecdotes covering a range of emotions.",Hornear pan los domingos me hace feliz,"Llevo más de 1000 días registrando mi estado de ánimo y mis actividades. Lo que empezó como un sumidero de tiempo acabó convirtiéndose en mi meditación diaria; mi momento para pensar en los momentos del día, ser sincero conmigo mismo y preguntarme ""¿cómo me siento?"". Esta charla explica cómo me sentí durante esos 1000 días y cómo mis actividades diarias influyen en mi estado de ánimo. Esta charla, que será mi más personal e íntima, contendrá visualizaciones de datos, estadísticas, análisis de series temporales y divertidas anécdotas.",https://photos.app.goo.gl/S5e6q6tV8QdRQZc5A,juandes,jdiossantos,,
jprnicolini,Juan Pablo Ruiz Nicolini,Opening up the data and processes of public tourism statistics in Argentina,"The National Directorate of Markets and Statistics (DNMyE) of the Undersecretariat of Strategic Development of the National Ministry of Tourism and Sports (MTyD), is responsible for tourism statistics in the framework of Argentina's national statistical system. The presentation tells the experience of how we implement reproducible and open workflows in a team that produces, consolidates and analyses public statistics.",Abrir los datos y procesos de las estadísticas públicas de turismo en Argentina,"La Dirección Nacional de Mercados y Estadísticas (DNMyE) de la Subsecretaría de Desarrollo Estratégico del Ministerio de Turismo y Deportes de la Nación (MTyD), es la responsable de las estadísticas de turismo en el marco del sistema estadístico nacional de Argentina. La presentación cuenta la experiencia de cómo implementamos flujos de trabajo reproducibles y abiertos en un equipo que produce, consolida y analiza estadísticas públicas.",https://tuqmano.ar/images/logo.png,TuQmano,TuQmano,,
kljordan,"Kari L. Jordan, PhD","csv,conf Community Building with The Carpentries Toolkit of IDEAS","The Toolkit of IDEAS (Inclusion, Diversity, Equity and Accessibility Strategies) is a practical resource that connects teaching foundational coding and data science skills to principles of inclusion, diversity, equity, and accessibility. In this session, Kari L. Jordan (Executive Director for The Carpentries) introduces the csv,conf community to the toolkit and identifies approaches for applying it to various community contexts.","csv,conf Construcción de comunidad con The Carpentries Toolkit of IDEAS","El conjunto de herramientas de IDEAS (Estrategias de inclusión, diversidad, equidad y accesibilidad) es un recurso práctico que conecta la enseñanza de habilidades básicas de codificación y ciencia de datos con los principios de inclusión, diversidad, equidad y accesibilidad. En esta sesión, Kari L. Jordan (Directora Ejecutiva de The Carpentries) presenta a la comunidad csv,conf el conjunto de herramientas e identifica enfoques para aplicarlo a diversos contextos comunitarios.",https://drive.google.com/file/d/1406zezupHEiC-RZkpLJ5xGz2zetWDoz9/view?usp=sharing,kariljordan,drkariljordan,,
kram,Karthik Ram,Keynote,,Cómo cultivar un ecosistema de código abierto (OSE) sostenible,"Los investigadores crean una amplia gama de artefactos como software de código abierto, datos abiertos y hardware de código abierto como parte de sus esfuerzos de investigación. En casi todos los campos del quehacer científico, el software de código abierto ha transformado la forma en que generamos, adquirimos, procesamos, modelamos y extraemos conclusiones de los datos. La creciente disponibilidad de estas herramientas de código abierto ha contribuido a mejorar el rigor, la calidad y la reproducibilidad de la investigación. Garantizar que estos productos sigan siendo funcionales a lo largo del tiempo es un reto importante. Además, las organizaciones que mantienen estos productos de código abierto también necesitan sostenerse a sí mismas. En esta charla, exploro los diversos factores que son necesarios para transformar un esfuerzo en un ecosistema de código abierto (OSE) sostenible y exitoso.",,,,,
ksullivan ,Kathleen Sullivan ,Speed Bumps on the Road to Innovating with Government Open Data ,"Along with improving transparency and efficiency, open government data is supposed to support entrepreneurship, in the form of user-friendly apps and other business innovations. But the reality often falls short of the ideal. Developers who want to use government data run into poor data quality and documentation, insufficient off-the-shelf data products, limited options for automation and other stumbling blocks. The Washington state (US) open government data team will highlight common development barriers and ways to overcome them, using examples from state agencies’ efforts to open data on transit, internet access, legal cannabis, licensing and more.",Obstáculos en el camino hacia la innovación con datos públicos abiertos,"Además de mejorar la transparencia y la eficiencia, se supone que los datos públicos abiertos apoyan el espíritu emprendedor, en forma de aplicaciones fáciles de usar y otras innovaciones empresariales. Pero la realidad no suele estar a la altura del ideal. Los desarrolladores que quieren utilizar datos públicos se topan con una documentación y calidad de datos deficientes, productos de datos comerciales insuficientes, opciones limitadas de automatización y otros obstáculos. El equipo de datos gubernamentales abiertos del estado de Washington (EE.UU.) destacará las barreras de desarrollo más comunes y las formas de superarlas, utilizando ejemplos de los esfuerzos de las agencias estatales para abrir datos sobre el tránsito, el acceso a Internet, el cannabis legal, la concesión de licencias y más.",,,,,
khoeberling,Katie Hoeberling,The role of data in addressing environmental and climate injustice,"Around the world, communities organize to address environmental pollution and respond to climate change. Data can provide support, prompting us to frame questions from new perspectives, emphasizing place-based stories and experiences, and connecting the broad range of people and institutions responsible for environmental governance and stewardship. But the barriers to data uptake are enormous – data collected by regulatory agencies, researchers, or mandated industry requirements are decontextualized. They do not adequately reflect local values and cultural knowledge that may be critically important to policy or regulatory change. On the other hand, communities must navigate complex laws and policies within dense legal landscapes before effectively sharing their data and experiences. This talk will explore the conditions necessary for making environmental data usable beyond its original intent, strengthening multi-directional flows to tell new stories and build informed solutions that center communities bearing the brunt of pollution and climate change. It will do so by highlighting efforts which are attempting to integrate community data in research and government decisions, and to make regulatory data more accessible to researchers, journalists, community organizations, lawyers, and others. We’ll discuss mechanisms and strategies for shifting social, political, and technical systems toward creating environmental governance and stewardship processes that work across sectors. ",,,https://www.openenvironmentaldata.org/people/katie-hoeberling,khoeberling,shrubberling,,
kbadger,Kelsey Badger,Data Management on the Front Lines: Managing Administrative Data at the Source,"Over the past decade, it has become increasingly common that funders require researchers to submit a data management plan detailing how data produced during the project will be documented, secured, and shared. However, there is no equivalent requirement for managing government data that is “born-administrative”, even if it is commonly used downstream for research purposes. This has resulted in an uneven patchwork of government data management practices that greatly impact the accessibility and usability of administrative data for both its original purposes and in any subsequent re-use. This talk will explore this challenge through the example of child welfare electronic case records in the United States. This data is a particularly complex case study due to both its sensitivity and the distributed nature of the child welfare service system, which relies heavily on privatized contractors. This creates a correspondingly long tail of data management needs that are often not addressed by top-down data governance policies. How can data management practices be incorporated earlier in child welfare data collection without further burdening overworked frontline staff? Are there lessons to be learned from the last decade of teaching researchers how to better manage their data? And whose responsibility is all this anyway? ",Gestión de datos en primera línea: Gestión de datos administrativos en origen,"En la última década, cada vez es más habitual que las entidades financiadoras exijan a los investigadores que presenten un plan de gestión de datos en el que se detalle cómo se documentarán, protegerán y compartirán los datos producidos durante el proyecto. Sin embargo, no existe un requisito equivalente para la gestión de los datos gubernamentales ""de origen administrativo"", aunque se utilicen habitualmente con fines de investigación. Esto ha dado lugar a un mosaico desigual de prácticas de gestión de datos gubernamentales que repercute enormemente en la accesibilidad y usabilidad de los datos administrativos tanto para sus fines originales como en cualquier reutilización posterior. Esta charla explorará este reto a través del ejemplo de los registros electrónicos de casos de bienestar infantil en Estados Unidos. Estos datos constituyen un caso de estudio especialmente complejo debido tanto a su sensibilidad como a la naturaleza distribuida del sistema de servicios de bienestar infantil, que depende en gran medida de contratistas privatizados. Esto crea una larga cola de necesidades de gestión de datos que a menudo no se abordan en las políticas descendentes de gobernanza de datos. ¿Cómo pueden incorporarse antes las prácticas de gestión de datos en la recopilación de datos de bienestar infantil sin sobrecargar aún más al personal de primera línea? ¿Se pueden extraer lecciones de la última década de enseñanza a los investigadores sobre cómo gestionar mejor sus datos? ¿Y de quién es la responsabilidad de todo esto?",https://opic.osu.edu/badger.60?width=500&aspect=p,,,,
kmacpherson,Kevin MacPherson,The Jigsaw Puzzle of Cellular Identity,"Could you tell you were looking at a picture of the Mona Lisa if someone scratched off 99% of the image before handing it to you?
Scientists who try to explore how various cell types in the body maintain their specialized identities face a similar problem. Experiments that attempt to obtain the epigenetic profile of a cell barely scratch the surface of all the information encoded within it. In isolation, these results may be uninterpretable.
Returning to the Mona Lisa example, if you took your 1% remaining image and overlaid it on top of the actual Mona Lisa, you would know instantly what the original image was. My talk would discuss how this same thing applies to the field of epigenetics and how data curation of small files can help solve this problem.",,,,,
lburin,Laia Domenech Burin,#Menstruacción: How much does it cost to menstruate?,"EcoFeminita (https://ecofeminita.com/) is a non-profit civil association which aims to show and address gender inequality by disseminating data, statistics, academic content and original research targeting all audiences. For this talk, I’d like to present our report called “How much does it cost to menstruate?”, which estimates the annual cost of menstrual management products —pads and tampons— based on data obtained through web scraping the government's open-data source Precios Claros (https://www.preciosclaros.gob.ar/). This report is done in the context of the #MenstruAcción campaign, which attempts to accomplish two main goals. Firstly, to expose the importance of providing menstrual management products for free, since they are a basic healthcare element to which not all the population have access. Secondly, to break down the menstruation taboo and promote research and socialization of data about this topic. My talk will address the main demands of the campaign, and the importance of using data in order to fight inequality. I will also explain our open-data methodology, the results of our report, and the recent challenges we’ve been facing due to the lack of transparency of Precios Claros.",,ecofeminita,ecofeminita,,
lacion,Laura Acion,Keynote - Collective Creation of Open Science / Creación Colectiva de Ciencia Abierta ,"Communities of practice are key to develop and adopt Open Science, particularly in the Global South. In this talk, we will reflect on the value of developing connections to co-create work experiences and environments that increase the use of Open Science mostly in, but not limited to, Latin America. We will also consider recommendations based on our experiences to further build sustainable, local, and contextualized Open Science communities with a global connection. Most of the talk will be in English with captions in English throughout. 

Las comunidades de práctica son clave para desarrollar y adoptar la Ciencia Abierta, particularmente en el Sur Global. En esta charla, reflexionaremos sobre el valor de desarrollar conexiones para co-crear experiencias y ambientes de trabajo que incrementan el uso de Ciencia Abierta mayormente en, pero no limitados a, América Latina. También consideraremos recomendaciones basadas en nuestras experiencias para seguir construyendo comunidades de Ciencia Abierta sostenibles, locales, contextualizadas y globalmente conectadas. La mayor parte de la charla será en inglés con subtítulos en inglés en todo momento.",,,,,
laalemany,Laura Alonso Alemany,Auditoría de sesgos para todos: avanzando en el territorio,"Los sistemas de toma de decisiones automatizados (recomendadores automáticos, clasificadores de riesgo crediticio, sistemas de reconocimiento de imágenes, traductores, entre otros) involucran aspectos cada vez más importantes de nuestras vidas, afectando incluso derechos humanos. Por esta razón, auditarlos se convierte en una necesidad. Sin embargo, los sistemas que involucran componentes de inteligencia artificial resultan especialmente difíciles de auditar, sobretodo en los casos en los que aplican aprendizaje automático, ya que suelen resultar opacos e ininteligibles para la persona que los inspecciona. Desde ámbitos académicos se han propuesto numerosos métodos para auditar estos sistemas, pero la mayor parte de propuestas involucran complejidades técnicas que excluyen a personas con experiencia relevante para la auditoría, como experiencia en discrimnación o en los contextos de aplicación de las tecnologías. En esta charla queremos presentar una herramienta y una metodología para facilitar el involucramiento de personas expertas, pero sin habilidades técnicas específicas, en la auditoría de sesgos de tecnologías del lenguaje. Describiremos cómo conceptualizamos los métodos de inspección de estas tecnologías poniendo el foco en las personas con experiencias relevantes, y haciendo transparentes las complejidades técnicas. Relataremos dos experiencias prácticas con personas expertas en muy diferentes tipos de sesgos y discriminaciones, que mostraron buena viabilidad de la herramienta. Finalmente, detallaremos nuestros planes a futuro: consolidar la herramienta como una librería de software, recopilar, disponibilizar y visibilizar recursos lingüísticos que permitan sistematizar el análisis de sesgos locales, en colaboración con equipos internacionales con los mismos objetivos, y finalmente impulsar la adopción de la metodología asociada a esta herramienta en organizaciones y empresas de nuestro entorno. Pueden encontrar una demo de la herramienta en https://huggingface.co/vialibre",https://www.famaf.unc.edu.ar/media/images/Alonso.e7111287.fill-1255x526.jpg,morlaicassiopea,morlaicassiopea,,
mhirsch,Mary Hirsch,Open research needs open (meta)data,"Metadata plays a key role in the scientific publication and dissemination process. It is only through metadata and identifiers that each contribution, from research data to article publication and beyond, becomes findable, accessible, interoperable and reusable. Persistent identifiers (PIDs) and their metadata are the backbone of scholarly communications, since only through them can the promise of sustainable access to research information be realized. This presentation will highlight the importance of open metadata in scholarly communications to recognize a wide range of contributions to science and as a way to build trust in research. We will also discuss the need for collaborative, community efforts to improve metadata creation and dissemination. Examples of organizations and researchers using open metadata will be presented.",,,,,
mtunga,Mahadia Tunga,Using Verbal Autopsy data to predict out-of-hospital causes of death,"Did you know that over 50% of people worldwide die outside health facilities? Thus, their cause of death is not known. Verbal autopsy(VA) is the survey-based method to determine symptoms or signs the deceased experienced before death. Using VA data and machine learning techniques, we can predict causes of death in areas where other forms of the autopsy are unavailable or not affordable such as in Low-income settings where more than 30% of people die outside health facilities. Having quality and adequate data on causes of death is important in understanding conditions of morbidity, which is an important aspect of quality healthcare interventions. I have developed a machine learning model to determine causes of death using bayesian networks.",https://theodi.org/person/mahadia-tunga/,,TungaMahadia,,
msharan,Malvika Sharan,Co-creating The Turing Way with global community,"The Turing Way - a community-led book for data science and research - originally emerged in response to the reproducibility crisis in science. Since 2019, the project has facilitated collaborations among an open, inclusive and collaborative community of researchers and organisations globally, enabling exchange of best practices in the guides for reproducibility, project design, collaboration, communication and ethics. The process of co-creation and the culture of collaboration is key to achieving The Turing Way’s mission to make data science accessible, comprehensible and beneficial for everyone. 
Collaboration at a global scale with stakeholders with different needs inherently puts maintenance and questions of access at the forefront, rejecting the notion of 'moving fast and breaking things'. The Turing Way has therefore continued to evolve its approaches to collaboration, community engagement, sustainability, governance, and goals, all while ensuring that we embed EDIA (equity, diversity, inclusion and accessibility) at the core of all our efforts. This talk discusses The Turing Way - or more precisely ""Way(s)"" - that has emerged to impact the landscape and culture of data science, addressing questions around situated knowledge and globalisation, accessible open infrastructure, digital skills, data management frameworks, reproducible workflows, research infrastructure roles, team science and more. All information and discussions are managed via GitHub: https://github.com/alan-turing-institute/the-turing-way/.",,malvikasharan,MalvikaSharan,,
mblack,Melissa Black,Co-creating The Turing Way with global community,"The Turing Way - a community-led book for data science and research - originally emerged in response to the reproducibility crisis in science. Since 2019, the project has facilitated collaborations among an open, inclusive and collaborative community of researchers and organisations globally, enabling exchange of best practices in the guides for reproducibility, project design, collaboration, communication and ethics. The process of co-creation and the culture of collaboration is key to achieving The Turing Way’s mission to make data science accessible, comprehensible and beneficial for everyone. 
Collaboration at a global scale with stakeholders with different needs inherently puts maintenance and questions of access at the forefront, rejecting the notion of 'moving fast and breaking things'. The Turing Way has therefore continued to evolve its approaches to collaboration, community engagement, sustainability, governance, and goals, all while ensuring that we embed EDIA (equity, diversity, inclusion and accessibility) at the core of all our efforts. This talk discusses The Turing Way - or more precisely ""Way(s)"" - that has emerged to impact the landscape and culture of data science, addressing questions around situated knowledge and globalisation, accessible open infrastructure, digital skills, data management frameworks, reproducible workflows, research infrastructure roles, team science and more. All information and discussions are managed via GitHub: https://github.com/alan-turing-institute/the-turing-way/. ",,,,,
mpatrick,Mariel Fritz Patrick,Cómo encontrar pistas para tus investigaciones en cientos de datasets usando Aleph,"Descripción: ¿Tienes bases de datos propias que te gustaría cruzar con otros datasets para ver si nombres de empresas y personas aparecen mencionados? ¿Tu redacción/organización trabaja con muchos PDF y necesitás una herramienta que extraiga el texto para poder hacer búsquedas de palabras clave? ¿Tienes una carpeta de documentos que quieres trabajar de manera segura con tus colegas?
¡Aleph puede ayudarte! Esta plataforma creada por OCCRP creada ayuda a periodistas, activistas e investigadores a ""seguir el rastro del dinero"". Su modelo de organización de datos, llamado Follow the Money (FTM) permite organizar grandes bases en un entorno seguro para encontrar conexiones entre personas y empresas a través del cruce de entidades en los datasets. 
Durante la sesión mostraremos cómo usar la herramienta a través de ejemplos concretos y de investigaciones reales. Nuestro demo en vivo, facilitará la conversación y preguntas con la audiencia.",,,,,
nbentley,Nokome Bentley,"Trust but verify: combining GPTs and CRDTs to empower researchers and
deter fraudsters","Recent advancements in artificial intelligence, particularly in
generative pre-trained transformers (GPTs) and other large language
models (LLMs), have the potential to increase the productivity of
researchers many times over. However, alongside the benefits of AI
comes the risk that these technologies could also accelerate the
creation of fraudulent scientific content. There is a growing concern
that we are on the verge of a deluge of ""deep fakes"" in academic
publishing, where AI-generated articles can easily deceive readers and
reviewers alike.

Conflict-free Replicated Data Types (CRDTs) are data structures that
allow for concurrent changes to a shared document across multiple
nodes without requiring constant coordination between them. CRDTs
enable real-time, distributed collaboration and version control
without relying on a centralized server. In most CRDT implementations,
each change to the document is accompanied by a unique identifier
representing the actor that made the change.

In this talk, I introduce an approach to scientific authoring that
combines the power of GPTs and CRDTs, allowing researchers to make use
of the capabilities of AI while improving the verifiability of
research provenance and integrating with established formats and tools
such as Jupyter Notebooks, Microsoft Word, and JATS XML.",,stencila,nokomebentley,,
pbernaldo,Paz Bernaldo,Resources and challenges for building global equitable open science communities,"Data ethics, data sharing and analysis are key for any deep dive into open science. Open Life Science (OLS) is a community-oriented non-profit organization attempting such a dive: designed to provide structured training and mentoring to curious academics, researchers, undergraduates and people working on participatory projects. OLS provides expert consulting, resources and peer-based networks to build projects and become open science ambassadors. In this talk we present our fully online 16 weeks program, and reflect on the resources needed to train international members across time zones, working on diverse problems, with different levels of infrastructure and support. We then explore the challenges in forming equitable global communities, such as collaboration between high and low-resource settings, language and accessibility barriers, and our experience about where allocating funding and resources can make a difference.",,pazbc,pazbyc,,
pdatta,Polash Datta,Covid Deaths: What Happens When News is Transformed into Data,"In 2020, during the pick of Covid-19 infection a good number of people in Bangladesh died with Covid-19 symptoms most of who were not tested for Covid-19. Although these deaths were reported in media outlets, there was no such platform that could provide a comprehensive and comparative view on these deaths. Dataful developed an interactive visual on these deaths by collected reports from eight Bangladeshi media outlets and converting those into data. I want to talk about how did we collect, checked, and converted the news into data and develop the interactive data visual.",,,polashdatta,,
rsefala,Raesetje Sefala,Constructing a Visual Dataset to Study the Effects of Spatial Apartheid in South Africa,"Over 27 years ago in South Africa, the Apartheid government forced non-European people to leave urban areas into neighborhoods like townships where they were marginalized in a controlled manner through laws and unfair budget constraints. In post-apartheid South Africa we still see no developments in townships and it is not easy to analyse what is happening in because in official government data like the census, the government lumps townships and suburbs together into a category known as formal residential neighborhoods. This masks the presence of townships, and prevents us from understanding whether or not they are changing after apartheid.  We created datasets that map all townships in South Africa together with these we use satellite imagery and machine learning techniques to analyse the evolution of neighborhoods post-apartheid. Even though apartheid has legally ended, photos show that townships are still very visibly different from suburbs. Our work segments out townships and analyses how they have changed over time, overlaying other datasets like government resource allocation data, there are disparities with urban areas. We give a few examples of what we’ve found, discuss our methodology, and talk about what we hope to do in the future.",https://media-exp1.licdn.com/dms/image/C5603AQF2sPdLw5aoAw/profile-displayphoto-shrink_800_800/0/1648848820091?e=2147483647&v=beta&t=HC4D2G-Acw6XirVtdY0dB-LwrBAOc1RNj1n_ZLJ4vk4,sefalab,bonjora,,
rsinclair,Rajiv Sinclair and Ayyub Ibrahim,​​Investigating police misconduct and migratory patterns,"​After gathering public records from hundreds of police departments and consolidating them into a single unified data structure, we were able to track individual police officers who move from one city to another after being accused of serious misconduct. 
​​In the course of investigating this and other systemic failures of the accountability system, we built a public database ( http://LLEAD.co ) and we cultivated a network of real-world practitioners who can put this tool to work on a day-to-day basis by using it to: defend individual members of the public against wrongful convictions ( https://ip-no.org ) , illustrate the mechanics of police impunity ( https://copwatchnola.wordpress.com ) , and advocate for meaningful changes on the policy level and beyond. 
​​In this talk, we will share techniques that we’ve developed for assembling individual profiles from a dynamic system made up of many messy data sources without any single unique identifier and we will discuss the challenges/opportunities for using data as a tool to transfer power to the public.",https://www.dropbox.com/s/idlwtpci488tebd/PDWblock.png?dl=1,ipno-llead,jeeves,,
rbiggs,Russ Biggs,OpenAQ: Wrangling the world's air quality data,"According to the World Health Organization, air pollution is estimated to cause 7 million premature deaths every year and 99% of the world’s population breathes unhealthy, polluted air. To begin to address the health effects of air pollution, air quality monitoring and data are essential to understanding health risk. Unfortunately, global monitoring data is siloed, disparate in format and accessibility. To address this challenge in data access, OpenAQ has developed the world’s largest open source and free data platform for air quality data. OpenAQ ingests millions of measurements a day across dozens of disparate sources and data formats to create a harmonized data repository of the world’s air quality data. This talk will explore how OpenAQ manages and wrangles data across the world’s air quality data sources. We will explore the wide range of data sources and formats and the challenges that arise when trying to harmonize data at a global scale.",https://russbiggs.com/img/russ.jpg,russbiggs,russ_biggs,,
rsinclair,Rajiv Sinclair,Investigating police misconduct and migratory patterns,"After gathering public records from hundreds of police departments and consolidating them into a single unified data structure, we were able to track individual police officers who move from one city to another after being accused of serious misconduct. 
In the course of investigating this and other systemic failures of the accountability system, we built a public database ( http://LLEAD.co ) and we cultivated a network of real-world practitioners who can put this tool to work on a day-to-day basis by using it to: defend individual members of the public against wrongful convictions ( https://ip-no.org ) , illustrate the mechanics of police impunity ( https://copwatchnola.wordpress.com ) , and advocate for meaningful changes on the policy level and beyond. 
In this talk, we will share techniques that we’ve developed for assembling individual profiles from a dynamic system made up of many messy data sources without any single unique identifier and we will discuss the challenges/opportunities for using data as a tool to transfer power to the public.",,ipno-llead,jeeves,,
sanapolsky,Sebastián Anapolsky,Using data to better understand and improve urban mobility,"Many of the big changes related to transportation in recent years have been the product of digitization and the availability of new sources of data. These data, combined with new techniques and processing tools, has offered great opportunities to better understand mobility patterns and design evidence-based public policies. This presentation will show how public publicly available data from the Buenos Aires urban area has been processed to analyze general mobility patterns and to better understand accessibility for different socioeconomic groups.",,sanapolsky,sanapols,,
sllópez,Sabrina Laura López,Towards a Community-Based Responsible Use of Health Data in Argentina and beyond,"Health data is, due to its sensitivity, internationally protected data. In this talk, we will share the experience of using health data for research in the Argentinian Public Health Research on Data Science and Artificial Intelligence for Epidemic Prevention (ARPHAI) project and the need to develop a Responsible Use of Data branch within ARPHAI. The objectives of this branch were initially focused on the project and rapidly reoriented towards raising awareness, problematizing, and mitigating the challenges related to the use of health data for the rest of the community at large. Some contributions of our work include developing an algorithm for de-identifying medical texts in Spanish, participating in the public consultation for updating Argentina’s Personal Data Law, and generating content to start addressing the challenges of using health data from different perspectives: patients, health professionals, data managers, and policymakers. We are working on further developing and sustaining a community of practice for the Responsible Use of Data in our region.",https://drive.google.com/file/d/1N7Ji2rZnhPLL2COOMSegTe1uXJhGeafi/view,SLLDeC,SLLDeC,,
scamargo,Sandro Camargo,Tell me who you hang out with and I'll tell you who you are: a collaborative analysis using social network analysis.,"Communities of practice are spaces where people share knowledge and contribute to individual and group objectives.  Knowing the different types of community members, the different ways they can participate, what kind of collaborations exist, and among whom is an important input to understand the community and to be able to take actions to improve differents aspecto of the community, like members' engagement, reach a wider audience, and increase diversity, among other.

In this talk, we will present an analysis of rOpenSci networks since its inception to recognize types and themes of collaborations, actors in those collaborations, and sub-communities, among other aspects.

We will explain how we collect the information to feed the networks (e.g. blog post authoring, event organization, package authoring, package review, among others), how we process it, and what kind of community management actions we can take based on the results obtained.

All the source code and the data that can be public will be shared on a repository. ",,,,,
scbaker ,Sarah Catherine Baker ,Solving Childhood Dementia: When data isn't enough ,"I work on a rare disease called Niemann Pick Disease Type C (NPC). NPC causes dementia, but rather than affecting elderly populations, NPC primarily affects children. Not only is NPC exceptionally rare, but individual patients often present very differently, making it hard to draw conclusions. My talk will be about the challenges of studying a disease when very little is know about it, and making the most of what little data you have. ",,,,,
sho,Salina Cheuk Ting Ho,Lessons from the history of literacy,"Open data efforts and initiatives tend to focus on the curation and publishing of accessible data for people to use. Conversations on open data commonly surrounds the technology and methodology used to advance these efforts, while there are not as many topics on the people who will be using these data. This talk proposes that the foundation of successful open data program lies in improving data literacy, especially if the intention of open data is public empowerment. Data literacy is the essential feedback loop to enhance the demand and quality of open data and its use. This talk will review the history of literacy (to read and write) and its relationship with industrialization to draw comparisons to our current data industry, and ultimately identify lessons to help us build better data literacy and open data programs.",,shohct,shohct,,
tgovindasamy,Tricia Govindasamy,Building Digital Democracy Solutions in Kenya through Data,"In Kenya, it remains difficult for both watchdogs and citizens to understand how financial resources are utilised since it decentralised services from national to county-level governments in 2013. Code for Africa built a tool that holds the government accountable by liberating data, called PesaYetu. PesaYetu is an interactive website designed to easily identify and track promises made by county government officials and visualise budget data. With PesaYetu, you can explore, interpret and report on data-driven stories affecting local communities. The tool is aimed at storytellers to help empower citizens wanting to engage their leaders on issues concerning policy and governance at the county level.",https://drive.google.com/file/d/1VsJWhwghh3ZkspTPVlXnFUtsxN25I4lv/view?usp=sharing,,triciagov,,
wasiqueira,William Antônio Siqueira,Agile Data Visualization with Dashbuilder,"Our local open data group (SJC digital) created data visualizations using Dashbuilder, a dashboard and data visualization tool. In this talk we would like to share how it is easy, no cost and fast to create consistent data visualizations using Dashbuilder. We will show examples of data visualizations created and made available in a few hours for different datasets including the so called ""Secret Budget"". Our vision is that Dashbuilder is a great tool for Open Data enthusiasts because its editor is available for any browser, it has no cost and run entirely on client!",https://github.com/jesuino,jesuino,,,
ysaibene,Yanina Noemí Bellini Saibene,Tell me who you hang out with and I'll tell you who you are: a collaborative analysis using social network analysis.,"Communities of practice are spaces where people share knowledge and contribute to individual and group objectives. Knowing the different types of community members, the different ways they can participate, what kind of collaborations exist, and among whom is an important input to understand the community and to be able to take actions to improve differents aspecto of the community, like members' engagement, reach a wider audience, and increase diversity, among other.

In this talk, we will present an analysis of rOpenSci networks since its inception to recognize types and themes of collaborations, actors in those collaborations, and sub-communities, among other aspects.

We will explain how we collect the information to feed the networks (e.g. blog post authoring, event organization, package authoring, package review, among others), how we process it, and what kind of community management actions we can take based on the results obtained.

All the source code and the data that can be public will be shared on a repository.",,yabellini,yabellini,,
yalberro,Yosune Chamizo Alberro,Gestor de mapas que promueve estándares abiertos y soberanía tecnológica para la investigación en México,"¿Es posible usar estándares abiertos desde instancias de gobierno?, ¿cómo podemos potenciar el impacto social de proyectos de investigación a través de una infraestructura de conocimiento geoespacial?, ¿cómo se planea un proyecto que promueve la autonomía e independencia tecnológica en México?, ¿es posible desarrollar componentes de software libre, abiertos y reutilizables en español para que se puedan usar en Iberoamérica? Este gestor de mapas integra información espacial estructurada de humanidades, ciencias y tecnologías con el uso fundamental de formatos como CSV, Geojson, Geopackage, PNG y TXT (para las tablas de metadatos), se tendrá acceso a capas con información sobre soberanía alimentaria, seguridad humana, agua, educación, energía, cambio climático, salud, entre otras.",,,_Yosune,,